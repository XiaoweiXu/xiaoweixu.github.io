<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8"/>
        <title>[ Xiaowei Xu | News ]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1.0"/>

        <!-- Font Awesome Icons -->
        <link rel="stylesheet" href="../css/font-awesome.min.css"/>

        <!-- Bootstrap -->
        <link href="../css/bootstrap.min.css" rel="stylesheet"/>
        <!--<link href="css/bootstrap.min.css" rel="stylesheet">-->

        <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
        <!--[if lt IE 9]>
         <script src="js/html5shiv.js"></script>
         <script src="js/respond.min.js"></script>
         <![endif]-->


        <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
        <script src="../js/jquery.min.js"></script>
        <!-- Include all compiled plugins (below), or include individual files as needed -->
        <script src="../js/bootstrap.min.js"></script>
        <script src="../js/menucollapse.js"></script>
        <script type="text/javascript" src="js/arrow78.js"></script>
        <script type="text/javascript" src="js/custom.js"></script>

        <body id="page-top" class="index">

            <!-- Navigation -->
            <nav class="navbar navbar-default navbar-fixed-top">
                <div class="container-fluid">
                    <!-- Brand and toggle get grouped for better mobile display -->
                    <div class="navbar-header">
                        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"  data-target="#bs-example-navbar-collapse-2" aria-expanded="false">
                            <span class="sr-only">Toggle navigation</span>
                            <span class="glyphicon glyphicon-search"></span>
                        </button>
                        <button id="button2" type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1" aria-expanded="false">
                            <span class="sr-only">Toggle navigation</span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                        </button>
                        <span><a href="http://www.gdghospital.org.cn/ziwang/index.php/"><img border="0" width="200" src="../images/gdsxxgbyjs_xxw.png"/></a></span>
                        <span><a href="http://english.hust.edu.cn/"><img border="0" width="40" src="../images/Hustseals.png"/></a></span>
                        <span><a href="https://www.ualberta.ca/index.html"><img border="0" width="40" src="../images/ua.png"/></a></span>
                        <span><a href="http://www.buffalo.edu/"><img border="0" width="40" src="../images/SUNY-Buffalo.png"/></a></span>
                        <span><a href="https://www.zju.edu.cn/english/"><img border="0" width="40" src="../images/zju.png"/></a></span>
                        <span><a href="https://www.nd.edu/"><img border="0" width="40" src="../images/nd3.png"/></a></span>
                    </div>

                    <!-- Collect the nav links, forms, and other content for toggling -->
                    <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                        <ul class="nav navbar-nav navbar-right">
                            <li class="dropdown">
                                <a class="dropdown-toggle" data-toggle="dropdown" href="#">
                                    Home<span class="caret"></span></a>
                                <ul class="dropdown-menu">
                                    <li><a href="../index.html#intro">Introduction</a></li>
                                    <!-- <li><a href="bio.html">Biography</a></li> -->
                                    <li><a href="../cv.html">CV (Web)</a></li>
                                    <li><a target="_blank" href="../cv_xiaoweixu.pdf">CV (PDF)</a></li>
                                </ul>
                            </li>
                            <li class="page-scroll">
                                <a href="../index.html#news">News</a>
                            </li>
                            <li class="dropdown">
                                <a class="dropdown-toggle" data-toggle="dropdown" href="#">
                                    Publications<span class="caret"></span></a>
                                <ul class="dropdown-menu">
                                    <li><a onclick="javascript:reset_menus();$('#tab-3-content').show();" href="../index.html#publications">Selected</a></li>
                                    <li><a href="../publications/">All</a></li>
                                </ul>
                            </li>
                            <!-- <li class="page-scroll">
                                <a href="talks/">Talks</a>
                            </li>
                            <li class="page-scroll">
                                <a href="index.html#courses">Courses</a>
                            </li>
                            <li class="page-scroll">
                                <a href="index.html#awards">Awards</a>
                            </li> -->
                            <li class="page-scroll">
                                <a href="../index.html#service">Service</a>
                            </li>
                            <li class="page-scroll">
                                <a href="../index.html#resources">Resources</a>
                            </li>
                            <!-- <li class="page-scroll">
                                <a target="_blank" href="http://dmsl.cs.ucy.ac.cy/projects.php">Grants</a>
                            </li> -->

                            <li class="page-scroll">
                                <a href="../index.html#contact">Contact</a>
                            </li>
                            <li class="page-scroll">
                                <a onclick="$('#bs-example-navbar-collapse-2').toggle();">
                                    <span class="glyphicon glyphicon-search"></span>
                                </a>
                            </li>
                        </ul>
                    </div><!-- /.navbar-collapse -->

                    <!-- search box submenu -->
                    <div class="collapse" id="bs-example-navbar-collapse-2">
                        <gcse:search></gcse:search>
                    </div>

                </div><!-- /.container-fluid -->
            </nav>

            <section>
                <!-- Place this tag where you want the search results to render -->
                <gcse:searchresults-only></gcse:searchresults-only>
            </section>

            <section id="tree" style="margin-top:50px">
                <div class="container">
                    <a href="../index.html">Xiaowei Xu</a> > Recordings
                </div>
            </section>


            <!-- Home Section -->
            <section id="home">
                <div class="container lead">

                    <h3> Nov, 2020 </h3>

                    <li><span class="label label-success">1 Nov, 2020</span><a href="https://arxiv.org/pdf/2006.03182.pdf">"MSDU-net: A Multi-Scale Dilated U-net for
                        Blur Detection" </a> </li>
                        <p> <span class="label label-default">extensive/intensive</span> 
                            Blur detection is the separation of blurred and clear regions
                                of an image, which is an important and challenging task in computer
                                vision. In this work, we regard blur detection as an image segmentation problem.</p>

                                The MSDU-net uses a
                                    group of multi-scale feature extractors with dilated convolutions to extract texture information at different scales. The U-shape architecture
                                    of the MSDU-net fuses the different-scale texture features and generates
                                    a semantic feature which allows us to achieve better results on the blur
                                    detection task.    </p>
                        <p> <span class="label label-default">comment</span> The main novelty lies on applying methdos in another domain to preblems in current domain.  

                    <li><span class="label label-success">2 Nov, 2020</span><a href="https://arxiv.org/pdf/1707.04912.pdf">"Improving Deep Pancreas Segmentation in CT
                        and MRI Images via Recurrent Neural
                        Contextual Learning and Direct Loss Function" </a> </li>
                        <p> <span class="label label-default">extensive</span> 
                            </p>The overall structure is FCN+LSTM, and the two modules are combined sequencially.

                            </p> LSTM is mainly for <b>contextual regularization</b>: segmentation results from successive slices need to be constrained for
                            shape consistence.
                            </p> Jaccard index loss: Segmentation-direct loss function can
                                avoid the data balancing issue during CNN training between the positive pancreas and negative background regions.
                        <p> <span class="label label-default">comment</span> Citation = 76, very initial work of combining FCN and LSTM.  

                    <li><span class="label label-success">2 Nov, 2020</span><a href="https://arxiv.org/pdf/1803.09860.pdf">"Three Birds One Stone: A General Architecture for
                        Salient Object Segmentation, Edge Detection and
                        Skeleton Extraction" </a> </li>
                        <p> <span class="label label-default">extensive/intensive</span> 
                            </p>In this paper, we aim at solving pixel-wise binary
                            problems, including salient object segmentation, skeleton extraction, and edge detection, by introducing a general architecture.

                            </p>In particular, we introduce a horizontal
                            cascade of encoders so as to gradually advance the feature
                            representations from the original CNN trunks. To better fuse
                            feature at different levels, the inputs of each encoder in our
                            architecture is densely connected to the outputs of its previous
                            encoder.
                            </p>Stringing these encoders together allows us to effectively
                            exploit features across different levels hierarchically to effectively
                            address multiple pixel-wise binary regression tasks. 
                            </p>Existing works: What they have in common is that each layer in the decoder (the
                            right part of each diagram in Fig. 2) can only receive features
                            from the backbone or its upper layers in the decoder. These
                            types of designs may work well for salient object detection
                            but may fail when applied to edge detection and skeleton
                            extraction (and vice versa). The fundamental reason behind
                            this is the fact that the feature representations formed in the
                            decoders are not powerful enough to deal with all of these
                            tasks.
                            </p>
                        <p> <span class="label label-default">comment</span> </p>
                        This is NOT a multi-task framework, but one which can be used for only one of these tasks.
                        </p> Good writing. Nice related work, and detailed motivation.

                        <li><span class="label label-success">3 Nov, 2020</span><a href="https://arxiv.org/pdf/1909.06121.pdf">"Dual Graph Convolutional Network for
                            Semantic Segmentation" </a> </li>
                            <p> <span class="label label-default">extensive</span> 
                                </p>Exploiting long-range contextual information is key for pixel-wise prediction tasks such as
                                semantic segmentation
    
                                </p>Our Dual Graph Convolutional Network (DGCNet) models the global
                                context of the input feature by modelling two orthogonal graphs in a single framework.
                                The first component models spatial relationships between pixels in the image, whilst the
                                second models interdependencies along the channel dimensions of the network’s feature
                                map. This is done efficiently by projecting the feature into a new, lower-dimensional
                                space where all pairwise interactions can be modelled, before reprojecting into the original
                                space. Code and models are made available to foster any further research
                                (https://github.com/lxtGH/GALD-DGCNet).

                                </p>Current state-of-the-art methods are all based on deep learning using fully convolutional
                                networks (FCNs) [32]. However, <b>the receptive field of an FCN grows slowly (only linearly)
                                with increasing depth in the network, and its limited receptive field is not able to capture
                                longer-range relationships between pixels in an image. Dilated convolutions [4, 49] have
                                been proposed to remedy this. However, the resulting feature representation is dominated by
                                large objects in the image, and consequently, performance on small objects is poor</b>. Another
                                direction has been to fuse multiscale features within the network [17, 31, 55] or to use LSTMs
                                to propagate information spatially [3, 40]. Recently, several methods based on self-attention
                                [14, 24, 43, 50] have also been used to learn an affinity map at each spatial position that
                                propagates information to its neighbours. However, the memory requirements of the large
                                affinity matrix renders these methods unsuitable for high resolution imagery.

                                </p> GCNs have recently been
                                applied to scene understanding tasks [8, 25, 26, 53], as they are able to globally propagate
                                information through the whole image in a manner that is conditional on the input.

                                </p>
                            <p> <span class="label label-default">comment</span> This is a great work which needs more attentions.                             
                        <li><span class="label label-success">4 Nov, 2020</span><a href="https://arxiv.org/pdf/1912.03383.pdf">"Deep Distance Transform for Tubular Structure Segmentation in CT Scans" </a> </li>
                            <p> <span class="label label-default">extensive</span> 
                                </p>Tubular structures are ubiquitous throughout the human
                                body, with notable examples including blood vessels, pancreatic duct and urinary tract. They occur in specific environments at the boundary of liquids, solids or air and surrounding tissues, and play a prominent role in sustaining
                                physiological functions of the human body.

                                </p>A tubular structure can be well represented by its
                                skeleton and the cross-sectional radius of each skeleton point.
    
                                </p>we propose to perform tubular structure segmentation by training a multitask deep network to predict not only a segmentation mask
                                for a tubular structure, but also a distance map, consisting
                                of the distance transform value from each tubular structure
                                voxel to the tubular structure surface, rather than a single skeleton/non-skeleton label
                                </p>We further quantize each dv into one of K bins by rounding dv to the nearest integer.  We do this quantization, because
                                training a deep network directly for regression is relatively
                                unstable, since outliers, i.e., the commonly existed annotation errors for medical images [41], cause a large error term,
                                which makes it difficult for the network to converge and
                                leads to unstable predictions.

                                <span><img border="0" width="1200" src="wang2019deep.png"/></a></span>
                                
                            <p> <span class="label label-default">comment</span> This idea may be also helpful for circle-like 2d-object segmentation. 
                                </p> Another thing is there are several threshold that are not explictly described in the paper. 
                        <li><span class="label label-success">2 Nov, 2020</span><a href="pdf">"" </a> </li>
                                <p> <span class="label label-default">extensive/intensive</span> 
                                    </p>
        
                                    </p>
                                <p> <span class="label label-default">comment</span> .                     
                        <li><span class="label label-success">2 Nov, 2020</span><a href="pdf">"" </a> </li>
                            <p> <span class="label label-default">extensive/intensive</span> 
                                </p>
    
                                </p>
                            <p> <span class="label label-default">comment</span> .                     
                        <li><span class="label label-success">2 Nov, 2020</span><a href="pdf">"" </a> </li>
                            <p> <span class="label label-default">extensive/intensive</span> 
                                </p>
    
                                </p>
                            <p> <span class="label label-default">comment</span> .                     
                        <li><span class="label label-success">2 Nov, 2020</span><a href="pdf">"" </a> </li>
                            <p> <span class="label label-default">extensive/intensive</span> 
                                </p>
    
                                </p>
                            <p> <span class="label label-default">comment</span> .                     
                        <li><span class="label label-success">2 Nov, 2020</span><a href="pdf">"" </a> </li>
                            <p> <span class="label label-default">extensive/intensive</span> 
                                </p>
    
                                </p>
                            <p> <span class="label label-default">comment</span> .                     
                        <li><span class="label label-success">2 Nov, 2020</span><a href="pdf">"" </a> </li>
                            <p> <span class="label label-default">extensive/intensive</span> 
                                </p>
    
                                </p>
                            <p> <span class="label label-default">comment</span> .                                                 
                    
                    </div>
                </div>
            </section>

            <hr class="star-primary">
            <footer>
                <small>
                    <center>
                        © 2016 | D. Zeinalipour. Credits: AR template
                        <a onclick="javascript:$('#credit').toggle();"><img border="0" src="images/ccby.png"/></a>
                        <div style="display:none;" id="credit">[AR template available under Creative Commons CC BY 4.0 licence:
                            <a href="https://github.com/dmsl/academic-responsive-template" target="_blank">
                                https://github.com/dmsl/academic-responsive-template
                            </a> ]
                        </div>
                    </center>
                </small>
            </footer>
            
        </body>
        
</html>
